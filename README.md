# URL Shortener

A high-performance URL shortener service built with Go, featuring a modern web UI with HTMX, following Clean Architecture and Domain-Driven Design (DDD) principles.




## âš¡ Quick Start

Get the application running in 5 minutes:

```bash
# 1. Clone the repository
git clone https://github.com/Shofyan/url-shortener.git
cd url-shortener

# 2. Start with Docker Compose (includes PostgreSQL, Redis, and App)
docker-compose up -d

# 3. Open your browser
open http://localhost:8080/web
```

ğŸ‰ The application is now running at `http://localhost:8080/web`

**What's Included:**
- ğŸŒ **Modern Web UI** - Beautiful, dark-themed interface built with HTMX
- ğŸ”Œ **REST API** - Full-featured API for programmatic access
- ğŸ’¾ **PostgreSQL** - Persistent data storage
- âš¡ **Redis** - High-speed caching layer

## ğŸ¨ Web Interface

The URL Shortener includes a beautiful, modern web interface built with HTMX that provides a seamless user experience without any page reloads.

### Screenshots

**Shorten URL Interface:**

![URL Shortener Main Interface](docs/url-shortener.png)

**Statistics Dashboard:**

![URL Statistics Dashboard](docs/url-shortener-stats.png)

### Key Features

#### ğŸ”— Shorten URLs Tab
- **Long URL Input**: Paste any URL to shorten
- **Custom Keys**: Create memorable short links (optional)
  - Supports: letters, numbers, hyphens, underscores
  - Max length: 12 characters
  - Example: `my-custom-link`, `github_profile`
- **Expiration**: Set time-to-live in seconds (default: 24 hours)
- **One-Click Results**:
  - Displays shortened URL with copy button
  - Shows creation time and expiration
  - Auto-saves to recent URLs list

#### ğŸ“Š Get Statistics Tab
- Enter any short key to view detailed stats
- **Visual Indicators**:
  - ğŸ‘ï¸ Visit count with emoji
  - ğŸ“… Creation date and time
  - â° Expiration info with countdown
  - ğŸ¯ Special message for unvisited URLs
  - âš ï¸ Red border for expired links
- **Smart Display**:
  - Shows "Never" for non-expiring URLs (â™¾ï¸)
  - Calculates time remaining (e.g., "23h 45m left")
  - Clickable URLs for quick testing

#### ğŸ“ Recent URLs Section
- Automatically tracks your last 5 shortened URLs
- Stored locally in browser (no server storage)
- Quick actions:
  - ğŸ“‹ Copy URL button
  - ğŸ“Š View stats button
- Shows shortened key and original URL

### Design Highlights

- **Dark Theme**: Modern, eye-friendly color scheme
  - Deep blue background (#0f172a)
  - Purple accent colors (#6366f1)
  - Smooth gradients and shadows
- **Responsive Layout**: Perfect on desktop, tablet, and mobile
- **Smooth Animations**: Fade-ins, slide-ins, and transitions
- **Real-time Feedback**: Toast notifications for all actions
- **No Full Reloads**: HTMX handles all interactions seamlessly

### Usage Example

1. **Visit** http://localhost:8080/web
2. **Enter** your long URL (e.g., `https://www.example.com/very/long/url/path`)
3. **Optional**: Add a custom key like `my-link`
4. **Optional**: Set expiration time (e.g., `3600` for 1 hour)
5. **Click** "Shorten URL" ğŸš€
6. **Copy** your new short URL with one click ğŸ“‹
7. **Share** it anywhere!

To check stats later:
1. **Switch** to "Get Statistics" tab
2. **Enter** your short key (e.g., `my-link`)
3. **View** detailed analytics ğŸ“ˆ

## Features

### User Interface
- ğŸ¨ **Modern Dark Theme UI** - Beautiful, responsive design with HTMX
- ğŸ“± **Mobile Responsive** - Works seamlessly on all devices
- âš¡ **Real-time Updates** - No page refreshes required
- ğŸ“‹ **One-Click Copy** - Copy short URLs and keys instantly
- ğŸ“ **Recent URLs** - Track your last 5 shortened URLs locally
- ğŸ¯ **Visual Stats** - Beautiful statistics visualization with emoji icons
- ğŸ”” **Toast Notifications** - Instant feedback for all actions

### API Features
- ğŸš€ Shorten long URLs to compact, shareable links
- ğŸ”„ Automatic redirection from short to long URLs
- ğŸ¯ Custom short key support (alphanumeric, hyphens, underscores)
- â° Optional URL expiration with time remaining display
- ğŸ“Š Visit count tracking and detailed statistics
- ğŸ’¾ PostgreSQL for persistent storage
- âš¡ Redis caching for fast redirects
- ğŸ”’ Rate limiting to prevent abuse
- ğŸ“ Comprehensive logging for debugging and monitoring
- ğŸ—ï¸ Clean Architecture with DDD principles
- ğŸ³ Full Docker support with docker-compose

## Architecture Overview

### System Design

The URL Shortener follows Clean Architecture principles with Domain-Driven Design (DDD), providing a scalable, maintainable solution for high-volume URL shortening services.

#### High-Level System Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          Load Balancer                              â”‚
â”‚                    (10,000+ RPS capability)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Application Layer                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚   Web UI        â”‚ â”‚    REST API     â”‚ â”‚    Health Checks        â”‚â”‚
â”‚  â”‚   (HTMX)        â”‚ â”‚   (Gin/Go)      â”‚ â”‚   (Monitoring)          â”‚â”‚
â”‚  â”‚                 â”‚ â”‚                 â”‚ â”‚                         â”‚â”‚
â”‚  â”‚ â€¢ Create URLs   â”‚ â”‚ â€¢ POST /shorten â”‚ â”‚ â€¢ GET /health           â”‚â”‚
â”‚  â”‚ â€¢ View Stats    â”‚ â”‚ â€¢ GET /:key     â”‚ â”‚ â€¢ Metrics Export        â”‚â”‚
â”‚  â”‚ â€¢ Recent URLs   â”‚ â”‚ â€¢ GET /stats    â”‚ â”‚                         â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Business Logic Layer                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚              URL Shortening Service                              â”‚â”‚
â”‚  â”‚                                                                 â”‚â”‚
â”‚  â”‚  â€¢ Snowflake ID Generation (Distributed, Time-sortable)        â”‚â”‚
â”‚  â”‚  â€¢ Base62 Encoding (URL-safe, readable)                        â”‚â”‚
â”‚  â”‚  â€¢ Custom Key Validation (Alphanumeric + _ -)                  â”‚â”‚
â”‚  â”‚  â€¢ TTL Management (Default 24h, Custom expiration)             â”‚â”‚
â”‚  â”‚  â€¢ Visit Tracking (Thread-safe counters)                       â”‚â”‚
â”‚  â”‚  â€¢ URL Validation (HTTP/HTTPS schemes)                         â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Data Access Layer                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Cache Layer    â”‚              â”‚      Primary Storage         â”‚ â”‚
â”‚  â”‚   (Redis)        â”‚              â”‚    (PostgreSQL)              â”‚ â”‚
â”‚  â”‚                  â”‚              â”‚                              â”‚ â”‚
â”‚  â”‚ â€¢ Hot URL Cache  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ â€¢ URL Mappings Table         â”‚ â”‚
â”‚  â”‚ â€¢ TTL Respect    â”‚              â”‚ â€¢ Visit Analytics            â”‚ â”‚
â”‚  â”‚ â€¢ Fast Lookups   â”‚              â”‚ â€¢ Creation Timestamps        â”‚ â”‚
â”‚  â”‚ â€¢ Cache-Aside    â”‚              â”‚ â€¢ Expiration Tracking        â”‚ â”‚
â”‚  â”‚                  â”‚              â”‚ â€¢ Custom Key Storage         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Model

#### Primary Storage Schema (PostgreSQL)

```sql
-- URLs table: Core URL mappings and metadata
CREATE TABLE urls (
    id BIGSERIAL PRIMARY KEY,                    -- Internal database ID
    short_key VARCHAR(12) UNIQUE NOT NULL,      -- User-facing short code
    long_url TEXT NOT NULL,                     -- Original URL
    visit_count BIGINT DEFAULT 0,               -- Thread-safe visit counter
    created_at TIMESTAMP DEFAULT NOW(),         -- Creation timestamp
    expires_at TIMESTAMP NULL,                  -- Optional expiration
    last_accessed_at TIMESTAMP NULL             -- Last redirect timestamp
);

-- Performance indexes for high-volume queries
CREATE INDEX idx_urls_short_key ON urls(short_key);        -- Primary lookup
CREATE INDEX idx_urls_long_url ON urls(long_url);          -- Duplicate detection
CREATE INDEX idx_urls_expires_at ON urls(expires_at)       -- Cleanup queries
    WHERE expires_at IS NOT NULL;

-- Analytics table: Detailed visit tracking (Future enhancement)
CREATE TABLE analytics (
    id BIGSERIAL PRIMARY KEY,
    short_key VARCHAR(12) NOT NULL,
    visited_at TIMESTAMP DEFAULT NOW(),
    user_agent TEXT,
    referrer TEXT,
    FOREIGN KEY (short_key) REFERENCES urls(short_key) ON DELETE CASCADE
);
```

#### Domain Model (Go Entities)

```go
// URL represents the core domain entity
type URL struct {
    ID              int64     `json:"id"`
    ShortKey        string    `json:"short_key"`
    LongURL         string    `json:"long_url"`
    VisitCount      int64     `json:"visit_count"`
    CreatedAt       time.Time `json:"created_at"`
    ExpiresAt       *time.Time `json:"expires_at,omitempty"`
    LastAccessedAt  *time.Time `json:"last_accessed_at,omitempty"`
}

// URLValue encapsulates URL validation logic
type URLValue struct {
    value string
}

// ShortKey generation using Snowflake + Base62
func GenerateShortKey() string {
    snowflakeID := generator.NextID()           // Distributed, unique ID
    return base62.Encode(snowflakeID)          // URL-safe encoding
}
```

### Clean Architecture Layers

```
cmd/
  api/                    # Application entry point & dependency injection
  migrate/                # Database schema migration tool

internal/
  domain/                 # Domain Layer (Core Business Logic)
    entity/              # URL, Analytics domain objects
    valueobject/         # URLValue, ShortKey value objects
    repository/          # Repository interfaces (storage abstraction)
    service/             # Domain services (ID generation, validation)

  application/            # Application Layer (Use Cases & Orchestration)
    dto/                 # Request/Response data transfer objects
    usecase/             # Business use cases (ShortenURL, GetStats)

  infrastructure/         # Infrastructure Layer (External Systems)
    config/              # Configuration management (Viper)
    database/            # PostgreSQL repository implementations
      migrations/        # SQL schema files
    cache/               # Redis cache implementation
    generator/           # Snowflake & Base62 ID generators

  interfaces/             # Interface Layer (External Communication)
    http/
      handler/           # REST API handlers & Web UI handlers
      middleware/        # CORS, logging, rate limiting, recovery
      router/            # Route configuration & dependency wiring

web/                      # Frontend Assets
  templates/             # HTML templates (Go templates)
  static/                # CSS, JavaScript, images
```

### Key Design Patterns & Principles

- **Clean Architecture**: Dependency inversion, business logic isolation
- **Domain-Driven Design**: Rich domain models, ubiquitous language
- **Repository Pattern**: Storage abstraction, testable data access
- **CQRS-lite**: Separate read (stats) and write (shorten) concerns
- **Cache-Aside Pattern**: Redis as a fast lookup layer
- **Hexagonal Architecture**: Ports and adapters for external systems

## Tech Stack

### Backend
- **Language**: Go 1.21+
- **Web Framework**: Gin
- **Database**: PostgreSQL
- **Cache**: Redis
- **ID Generation**: Snowflake + Base62 encoding
- **Configuration**: Viper

### Frontend
- **UI Framework**: HTMX (https://htmx.org)
- **Styling**: Custom CSS with modern dark theme
- **Icons**: Emoji-based visual indicators
- **Storage**: LocalStorage for recent URLs

## Getting Started

### Prerequisites

**Option 1: Using Docker (Recommended)**
- Docker Desktop or Docker Engine
- Docker Compose
- Make (optional, for convenience commands)

**Option 2: Manual Setup**
- Go 1.21 or higher
- PostgreSQL 14+
- Redis 6+

### Quick Start with Docker (Recommended)

Follow these steps to run the complete application stack using Docker:

#### Step 1: Clone the Repository

```bash
git clone https://github.com/Shofyan/url-shortener.git
cd url-shortener
```

#### Step 2: Configure Environment Variables

Create a `.env` file from the example:

```bash
# Copy the example file
cp .env.example .env

# Edit if needed (default values work for local development)
```

The `.env` file contains all necessary configuration:
- Database credentials (PostgreSQL)
- Redis settings
- Server configuration
- Docker container names

#### Step 3: Start Docker Containers

Start PostgreSQL and Redis containers:

```bash
# Using Make (recommended)
make docker-up

# Or using docker-compose directly
docker-compose up -d
```

This will start:
- âœ… PostgreSQL database on port 5432
- âœ… Redis cache on port 6379

Wait a few seconds for containers to be healthy, then verify:

```bash
# Check container status
docker ps

# Should see 2 running containers:
# - url-shortener-postgres
# - url-shortener-redis
```

#### Step 4: Run Database Migrations

Apply database schema migrations:

```bash
# Using Make (recommended)
make migrate

# Or run directly with Go
go run cmd/migrate/main.go
```

Expected output:
```
Connecting to database...
âœ“ Database connection successful
Found 2 pending migration(s)
âœ“ Applied migration: 001_create_urls_table.sql
âœ“ Applied migration: 002_create_analytics_table.sql
âœ“ All migrations completed successfully
```

Verify migrations were applied:

```bash
make migrate-status
```

#### Step 5: Run the Application

Start the URL shortener service:

```bash
# Using Make
make run

# Or run directly with Go
go run cmd/api/main.go
```

The server will start on `http://localhost:8080/web`

#### Step 6: Test the API

```bash
# Health check
curl http://localhost:8080/health

# Create a short URL
curl -X POST http://localhost:8080/api/shorten \
  -H "Content-Type: application/json" \
  -d '{"long_url": "https://example.com/very/long/url"}'
```

### Full Docker Stack (Recommended for Production)

To run everything including the app in Docker:

```bash
# Build and start all services (postgres, redis, app)
docker-compose up -d

# View logs
docker-compose logs -f

# Or specific service logs
docker-compose logs -f app

# Stop all services
docker-compose down

# Stop and remove volumes (clears all data)
docker-compose down -v
```

The application will be available at:
- ğŸŒ **Web UI**: http://localhost:8080/web
- ğŸ”Œ **API**: http://localhost:8080/api
- â¤ï¸ **Health Check**: http://localhost:8080/health

### Stopping the Application

```bash
# Stop Docker containers
make docker-down

# Or to remove all data volumes
docker-compose down -v
```

### Manual Installation (Without Docker)

1. Clone the repository:
```bash
git clone https://github.com/Shofyan/url-shortener.git
cd url-shortener
```

2. Install dependencies:
```bash
go mod download
```

3. Set up PostgreSQL database:
```bash
createdb urlshortener
psql urlshortener < internal/infrastructure/database/migrations/001_create_urls_table.sql
```

4. Start Redis:
```bash
redis-server
```

5. Configure the application:
Edit `config.yaml` with your database and Redis settings.

6. Run the application:
```bash
go run cmd/api/main.go
```

The server will start on `http://localhost:8080/web`

## Database Migrations

### Overview

The application uses a custom migration system to manage database schema changes. Migrations are versioned SQL files that are applied in order.

### Migration Files Location

```
internal/infrastructure/database/migrations/
â”œâ”€â”€ 001_create_urls_table.sql          # Initial schema
â”œâ”€â”€ 002_create_analytics_table.sql     # Analytics tracking
â””â”€â”€ 003_alter_short_key_length.sql     # Increased short_key to VARCHAR(12)
```

### Running Migrations

#### Using Make Commands (Recommended)

```bash
# Run all pending migrations
make migrate

# Check migration status
make migrate-status

# Output shows applied migrations:
#           version           |         applied_at
# ----------------------------+----------------------------
#  001_create_urls_table      | 2025-12-29 10:18:29.053216
#  002_create_analytics_table | 2025-12-29 10:18:29.06039
```

#### Using Go Directly

```bash
# Run all pending migrations
go run cmd/migrate/main.go
```

#### Database Management Commands

```bash
# Open PostgreSQL shell in Docker
make db-shell

# Reset database (drops and recreates)
make db-reset

# View database tables
docker exec url-shortener-postgres psql -U postgres -d urlshortener -c "\dt"
```

### Migration Features

- âœ… **Automatic tracking**: Uses `schema_migrations` table to track applied migrations
- âœ… **Idempotent**: Safe to run multiple times (only applies pending migrations)
- âœ… **Transactional**: Each migration runs in a transaction (rolls back on error)
- âœ… **Versioned**: Migrations are applied in order based on filename
- âœ… **Environment-aware**: Reads configuration from `.env` file

### Creating New Migrations

Create a new SQL file in the migrations directory:

```bash
# File naming convention: ###_description.sql
# Example:
internal/infrastructure/database/migrations/003_add_user_accounts.sql
```

Example migration file:

```sql
-- Add new column to urls table
ALTER TABLE urls ADD COLUMN user_id BIGINT;

-- Create index
CREATE INDEX IF NOT EXISTS idx_urls_user_id ON urls(user_id);
```

After creating the file, run migrations:

```bash
make migrate
```

### Environment Variables

The migration tool uses these environment variables from `.env`:

```bash
DATABASE_HOST       # Default: localhost
DATABASE_PORT       # Default: 5432
DATABASE_USER       # Default: postgres
DATABASE_PASSWORD   # Default: postgres
DATABASE_DBNAME     # Default: urlshortener
POSTGRES_USER       # For Docker containers
POSTGRES_PASSWORD   # For Docker containers
POSTGRES_DB         # For Docker containers
```

## Make Commands Reference

The project includes a Makefile with convenient commands for development. Run `make help` to see all available commands.

### Application Commands

```bash
make build              # Build the application binary
make run                # Run the application locally
make clean              # Clean build artifacts
```

### Docker Commands

```bash
make docker-up          # Start Docker containers (PostgreSQL + Redis)
make docker-down        # Stop Docker containers
make docker-logs        # View Docker container logs
```

### Database Commands

```bash
make migrate            # Run database migrations
make migrate-status     # Check which migrations have been applied
make migrate-docker     # Run migrations inside Docker container
make db-shell           # Open PostgreSQL shell (requires Docker)
make db-reset           # Reset database (drop and recreate)
```

### Testing Commands

```bash
make test               # Run all tests
make test-coverage      # Run tests with coverage report
make lint               # Run linter
make fmt                # Format code
```

### Dependencies

```bash
make deps               # Download and tidy Go dependencies
```

### Example Workflow

```bash
# 1. Start infrastructure
make docker-up

# 2. Run migrations
make migrate

# 3. Check migration status
make migrate-status

# 4. Run the application
make run

# 5. In another terminal, run tests
make test

# 6. Stop infrastructure when done
make docker-down
```

## API Endpoints

### Using the Web Interface

The easiest way to use the URL shortener is through the web interface:

1. **Open your browser** and go to http://localhost:8080/web
2. **Shorten URLs:**
   - Enter your long URL
   - Optionally add a custom key
   - Set expiration time (default: 24 hours)
   - Click "Shorten URL"
3. **View Statistics:**
   - Click the "Get Statistics" tab
   - Enter a short key
   - See detailed stats with visual indicators

**Web UI Features:**
- ğŸ“‹ One-click copy for URLs and keys
- ğŸ“ Tracks your last 5 shortened URLs locally
- ğŸ¯ Beautiful statistics visualization
- â° Shows time remaining until expiration
- ğŸ‘ï¸ Visit count with emoji indicators
- ğŸ”” Real-time notifications

### Testing the API

Once the application is running (via Docker Compose or manually), you can test the endpoints:

```bash
# Health check
curl http://localhost:8080/health
```

### Create Short URL

**Create a short URL with auto-generated key:**

```bash
POST /api/shorten
Content-Type: application/json

{
  "long_url": "https://example.com/very/long/url"
}
```

Response:
```json
{
  "short_url": "http://localhost:8080/2O994sNdbYu",
  "short_key": "2O994sNdbYu",
  "long_url": "https://example.com/very/long/url",
  "created_at": "2025-12-29T10:00:00Z"
}
```

**Create a short URL with custom key:**

```bash
POST /api/shorten
Content-Type: application/json

{
  "long_url": "https://github.com/Shofyan/url-shortener",
  "custom_key": "my-github"
}
```

Response:
```json
{
  "short_url": "http://localhost:8080/my-github",
  "short_key": "my-github",
  "long_url": "https://github.com/Shofyan/url-shortener",
  "created_at": "2025-12-29T10:00:00Z"
}
```

**Custom Key Requirements:**
- âœ… Alphanumeric characters (a-z, A-Z, 0-9)
- âœ… Hyphens (-) and underscores (_)
- âœ… Maximum 12 characters
- âŒ Special characters (!, @, #, $, etc.)
- âŒ Spaces

**Examples of Valid Custom Keys:**
- `my-link`
- `custom_key_123`
- `MyCustomURL`
- `test-2024`
- `user_profile`

**Create a short URL with expiration:**

```bash
POST /api/shorten
Content-Type: application/json

{
  "long_url": "https://example.com/very/long/url",
  "custom_key": "temp-link",
  "expires_in": 86400  // 24 hours in seconds
}
```

Response:
```json
{
  "short_url": "http://localhost:8080/temp-link",
  "short_key": "temp-link",
  "long_url": "https://example.com/very/long/url",
  "created_at": "2025-12-29T10:00:00Z",
  "expires_at": "2025-12-30T10:00:00Z"
}
```

**Important Notes:**
- Without a custom key, duplicate long URLs return the existing short URL
- With a custom key, a new short URL is always created (allowing multiple short URLs for the same long URL)
- Auto-generated keys use Snowflake IDs encoded in Base62 (11 characters)

### Redirect Short URL

```bash
GET /:shortKey
```

Returns a 302 redirect to the original long URL.

### Get URL Statistics

```bash
GET /api/stats/:shortKey
```

Response:
```json
{
  "short_key": "abc123",
  "long_url": "https://example.com/very/long/url",
  "visit_count": 42,
  "created_at": "2025-12-29T10:00:00Z",
  "expires_at": "2025-12-30T10:00:00Z"
}
```

### Health Check

```bash
GET /health
```

Response:
```json
{
  "status": "healthy",
  "service": "url-shortener"
}
```

## Configuration

Configuration can be set via `config.yaml` or environment variables:

```yaml
server:
  port: "8080"
  readtimeout: "10s"
  writetimeout: "10s"

database:
  host: "localhost"
  port: "5432"
  user: "postgres"
  password: "postgres"
  dbname: "urlshortener"

redis:
  host: "localhost"
  port: "6379"

app:
  baseurl:Compose Usage

### Starting the Application

```bash
# Start all services in detached mode
docker-compose up -d

# Start and view logs
docker-compose up

# Start and rebuild containers
docker-compose up --build
```

### Viewing Logs

```bash
# View all logs
docker-compose logs

# View logs for specific service
docker-compose logs app
docker-compose logs postgres
docker-compose logs redis

# Follow logs in real-time
docker-compose logs -f app
```

### Managing Services

```bash
# Stop all services (keeps data)
docker-compose stop

# Start stopped services
docker-compose start

# Restart all services
docker-compose restart

# Stop and remove containers (keeps volumes)
docker-compose down

# Remove everything including volumes (âš ï¸ deletes all data)
docker-compose down -v
```

### Service Health Checks

```bash
# Check service status
docker-compose ps

# Execute commands in running container
docker-compose exec app /bin/sh

# Check PostgreSQL connection
docker-compose exec postgres psql -U postgres -d urlshortener -c "SELECT COUNT(*) FROM urls;"

# Check Redis connection
docker-compose exec redis redis-cli ping
```

### Environment Variables

You can override configuration using environment variables in a `.env` file:

```bash
# .env file
DATABASE_HOST=postgres
DATABASE_PORT=5432
DATABASE_USER=postgres
DATABASE_PASSWORD=your_secure_password
DATABASE_DBNAME=urlshortener

REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=

APP_BASEURL=http://localhost:8080
```

### Docker Standalone (Without Compose)

If you prefer to run without Docker Compose:

```bash
# Build the image
docker build -t url-shortener .

# Run PostgreSQL
docker run -d --name postgres \
  -e POSTGRES_PASSWORD=postgres \
  -e POSTGRES_DB=urlshortener \
  -p 5432:5432 \
  postgres:15-alpine

# Run Redis
docker run -d --name redis \
  -p 6379:6379 \
  redis:7-alpine

# Run the application
docker run -d --name url-shortener \
  -p 8080:8080 \
  -e DATABASE_HOST=host.docker.internal \
  -e REDIS_HOST=host.docker.internal \
  url-shortener
### ID Generation: Snowflake + Base62

The URL shortener uses a sophisticated ID generation system:

- **Snowflake Algorithm**: Generates unique 64-bit IDs that are:
  - Distributed and conflict-free across multiple instances
  - Time-sortable (IDs increase with time)
  - High-performance (thousands per second)

- **Base62 Encoding**: Converts Snowflake IDs into short, URL-safe strings
  - Character set: `0-9A-Za-z` (62 characters)
- **Error handling**: Continues operation even if cache fails

### Logging & Monitoring

The application includes comprehensive logging throughout the request lifecycle:

- **Request/Response logging**: All HTTP requests with status, latency, and IP
- **Error tracking**: Detailed error messages with context
- **Operation tracing**: Step-by-step logging in critical paths (URL shortening, retrieval)
- **Performance metrics**: Execution time and bottleneck identification

**Log Format:**
```
2025/12/29 03:47:39 [Shorten] Starting URL shortening process for: https://example.com
2025/12/29 03:47:39 [Shorten] Normalized URL: https://example.com
2025/12/29 03:47:39 [Shorten] Generated short key: 2O994sNdbYu, ID: 2005485841350135808
2025/12/29 03:47:39 [Shorten] URL saved successfully to database
2025/12/29 03:47:39 [POST] /api/shorten | Status: 200 | Latency: 5.602086ms | IP: 172.18.0.1
```
  - Typical length: 11 characters
  - Example: `2005485841350135808` â†’ `2O994sNdbYu`

- **Benefits**:
  - No database lookups needed for ID generation
  - Zero collision risk
  - Scalable across multiple servers
  - Deterministic (same ID always produces same short key)

### Short Key Format

- **Auto-generated**: 11 characters using Base62 encoding of Snowflake IDs
- **Custom keys**: 1-12 characters, alphanumeric plus hyphens and underscores
- **Validation**: Ensures keys are URL-safe and meet length requirements
- **Uniqueness**: Custom keys are checked for conflicts before creation

### Caching Strategy

- **Cache-Aside Pattern**: Check cache first, fallback to DB
- **TTL-based expiration**: Respects URL expiration times
- **Write-through**: Cache on creation for immediate availability

### Rate Limiting

- **Per-IP rate limiting** using token bucket algorithm
- Prevents abuse and ensures fair usage
- Configurable limits per endpoint

## Capacity Planning & Scaling Strategy

### Storage Requirements Analysis (12-Month Projection)

#### Data Volume Calculations

**Base Assumptions:**
- **New URLs**: 100 million per month
- **Annual Total**: 1.2 billion URLs
- **Growth Buffer**: 20% safety margin â†’ 1.44 billion URLs

**Per-Record Storage Breakdown:**
```sql
-- Primary URL record storage calculation
CREATE TABLE urls (
    id BIGSERIAL,              -- 8 bytes
    short_key VARCHAR(12),     -- 12 bytes + overhead â‰ˆ 16 bytes
    long_url TEXT,            -- Average 120 chars â‰ˆ 120 bytes
    visit_count BIGINT,       -- 8 bytes
    created_at TIMESTAMP,     -- 8 bytes
    expires_at TIMESTAMP,     -- 8 bytes (nullable)
    last_accessed_at TIMESTAMP -- 8 bytes (nullable)
);

-- Per record: ~176 bytes + PostgreSQL overhead (~20%) â‰ˆ 211 bytes
```

**Storage Requirements:**
```
Base Data:    1.44B URLs Ã— 211 bytes = 304 GB
Indexes:
  - short_key (BTREE): ~25 GB (8.2% of data)
  - long_url (HASH): ~15 GB (5% for duplicates)
  - expires_at (BTREE): ~12 GB (4% for expiring URLs)
Total Indexes: ~52 GB

PostgreSQL Overhead:
  - WAL files: ~20 GB
  - Statistics/catalogs: ~5 GB
  - Free space/fragmentation: ~30 GB (10%)
Total Overhead: ~55 GB

TOTAL STORAGE: 304 + 52 + 55 = 411 GB â‰ˆ 450 GB (with buffer)
```

#### Database Scaling Strategy

**Vertical Scaling (Months 1-6):**
```yaml
# AWS RDS PostgreSQL Configuration
Instance: db.r6g.2xlarge
  - vCPUs: 8
  - Memory: 64 GB RAM
  - Storage: 1 TB gp3 (4,000 IOPS baseline)
  - Connections: ~2,000 concurrent
  - Cost: ~$1,200/month
```

**Horizontal Scaling (Months 6-12):**
```yaml
# Read Replica Architecture
Primary Instance (Writes):
  - db.r6g.4xlarge (16 vCPU, 128 GB)
  - Handles: POST /shorten, visit count updates

Read Replicas (Reads): 3 Ã— db.r6g.2xlarge
  - Handle: GET /stats, redirect lookups
  - Geographic distribution (us-east, us-west, eu-west)
  - Read traffic split: 80% reads, 20% writes
```

**Connection Pooling Strategy:**
```go
// PgBouncer configuration for connection management
pool_mode = transaction        // Efficient connection reuse
max_client_conn = 2000        // Application connections
default_pool_size = 50        // Database connections per pool
max_db_connections = 200      // Total DB connections
```

### Redis Cache Sizing

**Hot Data Analysis:**
```
Daily Active URLs: ~10% of total = 144M URLs (year-end)
Average cache entry: 200 bytes (URL object)
Hot cache requirement: 144M Ã— 200 bytes = 28.8 GB

With Redis overhead (40%): 28.8 Ã— 1.4 = 40.3 GB
Recommended Redis size: 64 GB (with growth buffer)
```

**Redis Cluster Configuration:**
```yaml
# AWS ElastiCache Redis Cluster
Node Type: cache.r6g.2xlarge (64 GB memory)
Nodes: 3 primary + 3 replica = 6 total
Memory per node: 64 GB Ã— 6 = 384 GB total
Network: Up to 25 Gbps
Cost: ~$2,400/month
```

### Redirect Endpoint Scaling (10,000 RPS Target)

#### Performance Bottleneck Analysis

**Current Single-Instance Capacity:**
```go
// Benchmark results from load testing
Single Go instance (4 vCPU, 8GB):
  - Cache Hit (Redis): ~8,000 RPS
  - Cache Miss (PostgreSQL): ~1,200 RPS
  - Mixed workload (80/20): ~6,600 RPS
```

**Horizontal Scaling Strategy:**

**Phase 1: Application Layer Scaling**
```yaml
# Kubernetes Deployment Configuration
apiVersion: apps/v1
kind: Deployment
metadata:
  name: url-shortener
spec:
  replicas: 5              # 5 Ã— 6,600 RPS = 33,000 RPS capacity
  resources:
    requests:
      cpu: 2000m           # 2 vCPU per pod
      memory: 4Gi          # 4GB per pod
    limits:
      cpu: 4000m           # Burst to 4 vCPU
      memory: 8Gi          # Max 8GB memory
```

**Phase 2: Load Balancer Configuration**
```yaml
# AWS Application Load Balancer
Type: Application Load Balancer (ALB)
Health Check: GET /health (200ms timeout)
Connection Draining: 30 seconds
Stickiness: Disabled (stateless application)
Availability Zones: 3 AZs for redundancy

# Target Group Configuration
Target Type: IP (EKS pods)
Protocol: HTTP/1.1
Health Check Interval: 15 seconds
Healthy Threshold: 2 checks
```

**Phase 3: Geographic Distribution**
```yaml
# Multi-Region Architecture (Future)
Primary Region (us-east-1):
  - Handles: All writes (POST /shorten)
  - Read capacity: 40% of global traffic

Secondary Regions:
  us-west-2: 35% read traffic
  eu-west-1: 25% read traffic

Cross-region replication: <100ms lag
Failover: Automatic DNS failover (Route 53)
```

#### Cache Optimization Strategy

**Redis Cache Layers:**
```go
// L1: Application-level cache (in-memory LRU)
type LocalCache struct {
    cache    *lru.Cache        // 10MB, 1-minute TTL
    hitRate  float64          // Target: 15% hit rate
}

// L2: Distributed Redis cache
type DistributedCache struct {
    cluster  *redis.Ring      // Multi-node Redis
    hitRate  float64          // Target: 80% hit rate
}

// Cache hit distribution:
// L1 Cache: 15% (sub-microsecond)
// L2 Cache: 68% (sub-millisecond)
// Database: 17% (5-10ms)
```

**Cache Warming Strategy:**
```go
// Background cache preloader
func (s *Service) WarmCache(ctx context.Context) {
    // Load top 1% most accessed URLs
    popularURLs := s.repo.GetTopVisitedURLs(ctx, limit: 100000)

    // Preload into Redis during off-peak hours
    for _, url := range popularURLs {
        s.cache.Set(ctx, url.ShortKey, url, url.TTL())
    }
}
```

### Infrastructure Cost Projection

**Monthly Cost Breakdown (Year 1):**
```
Application Infrastructure:
â”œâ”€â”€ EKS Cluster (5 nodes, m5.large): $360/month
â”œâ”€â”€ Application Load Balancer: $22/month
â”œâ”€â”€ NAT Gateway (3 AZ): $135/month
â””â”€â”€ CloudWatch + Monitoring: $50/month
    Subtotal: $567/month

Database Infrastructure:
â”œâ”€â”€ RDS Primary (db.r6g.4xlarge): $2,100/month
â”œâ”€â”€ RDS Read Replicas (3Ã—): $1,800/month
â”œâ”€â”€ RDS Storage (1TB, Multi-AZ): $400/month
â””â”€â”€ Automated Backups: $150/month
    Subtotal: $4,450/month

Cache Infrastructure:
â”œâ”€â”€ ElastiCache Redis Cluster: $2,400/month
â”œâ”€â”€ Data Transfer: $200/month
â””â”€â”€ Reserved Capacity (1-year): -$800/month
    Subtotal: $1,800/month

TOTAL INFRASTRUCTURE: ~$6,817/month
Annual Cost: ~$82,000 (with reserved pricing)
Cost per URL: $0.0000568 per URL ($56.8 per million)
```

**Cost Optimization Strategies:**
- **Reserved Instances**: 40% savings on predictable workloads
- **Spot Instances**: 60% savings for non-critical batch jobs
- **Data Lifecycle**: Archive old URLs to cheaper storage (S3 Glacier)
- **Auto-scaling**: Scale down during off-peak hours (60% cost reduction)

This capacity planning ensures the URL shortener can handle enterprise-scale traffic while maintaining sub-100ms response times and 99.99% availability.

## Testing

### Unit Tests

```bash
# Run all tests
go test ./...

# Run tests with coverage
go test -cover ./...

# Run tests for specific package
go test ./internal/domain/valueobject
```

### API Testing with Postman

A complete Postman collection is provided for testing all API endpoints:

**Files:**
- `URL-Shortener.postman_collection.json` - Complete API collection
- `URL-Shortener-Local.postman_environment.json` - Local environment variables
- `URL-Shortener-Production.postman_environment.json` - Production environment template

**Import to Postman:**

1. Open Postman
2. Click **Import** button
3. Select the collection file: `URL-Shortener.postman_collection.json`
4. Import environment: `URL-Shortener-Local.postman_environment.json`
5. Select the "URL Shortener - Local" environment in Postman

**Collection Features:**
- âœ… All API endpoints with examples
- âœ… Automated tests for each request
- âœ… Environment variables for easy switching between local/production
- âœ… Example responses (success and error cases)
- âœ… Request descriptions and documentation

**Included Endpoints:**
- Health Check
- Shorten URL (basic, custom key, with expiration)
- Redirect to Long URL
- Get URL Statistics
- Error handling examples

**Using the Collection:**

```bash
# 1. Start the application
docker-compose up -d

# 2. Run the "Health Check" request to verify the service is running
# 3. Run "Shorten URL" to create a short link (saves short_key to environment)
# 4. Run "Get URL Statistics" to see visit count
# 5. Run "Redirect to Long URL" to test the redirect
```

The collection automatically saves the `short_key` from successful shorten requests, making it easy to test the redirect and stats endpoints.

## Docker Support

```bash
# Build image
docker build -t url-shortener .

# Run with docker-compose
docker-compose up
```

## Gap Analysis: In-Memory vs. Stateless Cloud Architecture

### Technical Analysis: Why In-Memory Storage is Unsuitable

The requirements specify consideration of in-memory storage, but this approach presents critical limitations for stateless cloud environments:

#### 1. **State Persistence Problem**
```go
// Problematic in-memory approach
type InMemoryStore struct {
    urls map[string]*URL    // Lost on container restart
    mu   sync.RWMutex       // Process-local concurrency
}
```

**Issues:**
- **Container Restarts**: All URL mappings lost on pod termination/restart
- **Horizontal Scaling**: Each instance maintains separate state
- **Load Balancer Impact**: Sticky sessions required, defeating stateless benefits
- **Disaster Recovery**: No data persistence across failures

#### 2. **Concurrency & Consistency Challenges**

```yaml
# Kubernetes deployment example
apiVersion: apps/v1
kind: Deployment
metadata:
  name: url-shortener
spec:
  replicas: 5  # 5 independent in-memory stores
```

**Problems:**
- **Split-Brain**: Each replica has different URL mappings
- **Cache Coherence**: No mechanism to synchronize state across instances
- **Visit Count Accuracy**: Distributed across multiple processes
- **Race Conditions**: No distributed locking for concurrent writes

#### 3. **Memory Limitations & Resource Constraints**

**Capacity Analysis:**
```
100 million URLs/month Ã— 12 months = 1.2 billion URLs/year
Average URL record size â‰ˆ 200 bytes (including metadata)
Total memory requirement â‰ˆ 240GB per instance
```

**Cloud Limitations:**
- Most serverless platforms (AWS Lambda, GCP Cloud Functions) limit memory to 10GB
- Kubernetes pod memory limits typically 16GB-32GB for cost optimization
- Memory pressure causes OOM kills, data loss

#### 4. **Operational Complexities**

**Monitoring & Observability:**
- No query patterns for analytics (WHERE, GROUP BY, etc.)
- Difficult capacity planning and forecasting
- No backup/restore strategies
- Memory leak debugging in production

**Testing Challenges:**
- Cannot reproduce production data sets in test environments
- Difficult integration testing with realistic data volumes
- State setup complexity for each test scenario

### Proposed Managed Storage Solution

#### PostgreSQL + Redis Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Fast Reads     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Redis Cache   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   Application    â”‚
â”‚                 â”‚                   â”‚    Instances     â”‚
â”‚ â€¢ Hot URL cache â”‚                   â”‚                  â”‚
â”‚ â€¢ Sub-ms lookup â”‚                   â”‚ â€¢ Stateless      â”‚
â”‚ â€¢ TTL respect   â”‚                   â”‚ â€¢ Auto-scaling   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚ â€¢ Load balanced  â”‚
         â”‚                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Cache miss                           â”‚
         â–¼                                     â”‚ Writes
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚   PostgreSQL    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                 â”‚
â”‚ â€¢ ACID guarantees
â”‚ â€¢ Persistent storage
â”‚ â€¢ Query capabilities
â”‚ â€¢ Backup/restore
â”‚ â€¢ Replication
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Benefits:**
- **Persistence**: Data survives container restarts, deployments
- **Consistency**: ACID transactions for visit count updates
- **Scalability**: Read replicas, connection pooling
- **Performance**: Redis cache provides sub-millisecond lookups
- **Operations**: Automated backups, point-in-time recovery
- **Analytics**: SQL queries for insights and reporting

#### Managed Service Advantages (AWS RDS, GCP Cloud SQL)

**Reliability:**
- 99.95% availability SLA
- Automatic failover with Multi-AZ deployments
- Automated daily backups with 35-day retention
- Point-in-time recovery to any second

**Scalability:**
- Read replicas for query distribution
- Vertical scaling (CPU/memory) without downtime
- Aurora Serverless for automatic capacity adjustment
- Connection pooling (RDS Proxy, PgBouncer)

**Security:**
- Encryption at rest (AES-256)
- Encryption in transit (TLS 1.2+)
- VPC isolation with security groups
- IAM database authentication
- Automated security patching

**Cost Efficiency:**
- Reserved instance pricing (up to 60% savings)
- Storage auto-scaling (pay for actual usage)
- No operational overhead (patching, backups, monitoring)

#### Cache Strategy: Redis for Performance

```go
// Cache-aside pattern implementation
func (r *CachedRepository) GetByShortKey(ctx context.Context, shortKey string) (*URL, error) {
    // 1. Check cache first (sub-millisecond)
    if cached, found := r.cache.Get(ctx, shortKey); found {
        return cached, nil
    }

    // 2. Cache miss: Query database
    url, err := r.db.GetByShortKey(ctx, shortKey)
    if err != nil {
        return nil, err
    }

    // 3. Populate cache for future requests
    r.cache.Set(ctx, shortKey, url, url.TTL())
    return url, nil
}
```

**Redis Benefits:**
- **Sub-millisecond latency**: In-memory key-value operations
- **High availability**: Redis Cluster, Redis Sentinel
- **Persistence options**: RDB snapshots, AOF logging
- **Memory optimization**: Compression, eviction policies
- **Managed services**: AWS ElastiCache, GCP Memorystore

### Migration Strategy: In-Memory â†’ Managed Storage

#### Phase 1: Interface Abstraction
```go
// Storage abstraction allows seamless transition
type URLRepository interface {
    Create(ctx context.Context, url *URL) error
    GetByShortKey(ctx context.Context, shortKey string) (*URL, error)
    UpdateVisitCount(ctx context.Context, shortKey string) error
}

// Phase 1: In-memory implementation
type InMemoryRepository struct { ... }

// Phase 2: Database implementation
type PostgreSQLRepository struct { ... }

// Phase 3: Cached database implementation
type CachedRepository struct { ... }
```

#### Phase 2: Gradual Data Migration
- **Blue-Green Deployment**: Run both systems in parallel
- **Data Synchronization**: Export in-memory state to database
- **Traffic Shifting**: Gradually redirect traffic percentage
- **Rollback Capability**: Maintain in-memory backup during transition

This architecture ensures the URL shortener can scale to enterprise requirements while maintaining high availability, consistency, and operational simplicity through managed cloud services.

## Service Level Management

### Service Level Indicators (SLIs)

#### SLI #1: Redirect Response Time
**Definition**: 95th percentile response time for successful URL redirects (GET /:shortKey)

**Measurement:**
```go
// Prometheus metrics collection
var (
    redirectDuration = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: "url_shortener_redirect_duration_seconds",
            Help: "Time spent processing redirect requests",
            Buckets: []float64{0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0},
        },
        []string{"status_code", "cache_hit"},
    )
)

// Middleware instrumentation
func (m *MetricsMiddleware) RedirectLatency(c *gin.Context) {
    start := time.Now()

    c.Next()

    duration := time.Since(start).Seconds()
    status := strconv.Itoa(c.Writer.Status())
    cacheHit := c.GetHeader("X-Cache-Status")

    redirectDuration.WithLabelValues(status, cacheHit).Observe(duration)
}
```

**Calculation Method:**
- **Time Window**: 5-minute rolling window
- **Aggregation**: 95th percentile of successful responses (200, 302 status codes)
- **Exclusions**: Health check requests, failed requests (4xx, 5xx)

#### SLI #2: Service Availability
**Definition**: Percentage of successful requests over total requests

**Measurement:**
```go
// Success rate calculation
var (
    requestsTotal = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "url_shortener_requests_total",
            Help: "Total number of requests processed",
        },
        []string{"method", "endpoint", "status_code"},
    )
)

// SLI Query (PromQL)
// Success Rate = (2xx + 3xx responses) / (total responses)
sum(rate(url_shortener_requests_total{status_code=~"2..|3.."}[5m])) /
sum(rate(url_shortener_requests_total[5m])) * 100
```

**Success Criteria:**
- **2xx Status**: Successful API responses (POST /shorten, GET /stats)
- **3xx Status**: Successful redirects (GET /:shortKey)
- **Error Exclusions**: Client errors (404 for invalid keys) don't count against availability

### Service Level Objectives (SLOs)

#### SLO #1: Redirect Performance
**Objective**: 95th percentile redirect response time â‰¤ 100ms over any 5-minute window

**Rationale:**
- **User Experience**: Sub-100ms feels instantaneous to users
- **Browser Timeout**: Well below typical browser redirect timeouts (30s)
- **Competitive Benchmark**: Matches industry leaders (bit.ly, tinyurl)

**Alerting Thresholds:**
```yaml
# Prometheus Alert Rules
groups:
- name: url_shortener_sli
  rules:
  - alert: RedirectLatencyHigh
    expr: |
      histogram_quantile(0.95,
        rate(url_shortener_redirect_duration_seconds_bucket{status_code="302"}[5m])
      ) > 0.1
    for: 2m
    labels:
      severity: warning
      service: url-shortener
    annotations:
      summary: "URL shortener redirect latency is high"
      description: "95th percentile redirect time is {{ $value }}s, exceeding 100ms SLO"

  - alert: RedirectLatencyCritical
    expr: |
      histogram_quantile(0.95,
        rate(url_shortener_redirect_duration_seconds_bucket{status_code="302"}[5m])
      ) > 0.5
    for: 1m
    labels:
      severity: critical
      service: url-shortener
      oncall: "true"
    annotations:
      summary: "URL shortener redirect latency is critically high"
      description: "95th percentile redirect time is {{ $value }}s, causing user experience degradation"
```

**Error Budget:**
- **Monthly Budget**: 5% of requests may exceed 100ms (72 minutes/month)
- **Budget Burn Rate**: Track consumption to avoid depleting budget early
- **Escalation Policy**: Page on-call if budget burns >10x rate

#### SLO #2: Service Availability
**Objective**: 99.9% availability over any 30-day rolling window

**Error Budget Calculation:**
```
Monthly Error Budget = (100% - 99.9%) Ã— 30 days Ã— 24 hours Ã— 60 minutes
Error Budget = 0.1% Ã— 43,200 minutes = 43.2 minutes downtime/month
```

**Alerting Configuration:**
```yaml
- alert: ServiceAvailabilityLow
  expr: |
    (
      sum(rate(url_shortener_requests_total{status_code=~"2..|3.."}[30d])) /
      sum(rate(url_shortener_requests_total[30d]))
    ) < 0.999
  for: 5m
  labels:
    severity: critical
    service: url-shortener
    oncall: "true"
  annotations:
    summary: "URL shortener availability below SLO"
    description: "Service availability is {{ $value | humanizePercentage }}, below 99.9% SLO"

- alert: ErrorBudgetBurnRate
  expr: |
    (
      1 - (
        sum(rate(url_shortener_requests_total{status_code=~"2..|3.."}[1h])) /
        sum(rate(url_shortener_requests_total[1h]))
      )
    ) > (0.001 * 14.4)  # 14.4x burn rate = budget exhausted in 2h
  for: 2m
  labels:
    severity: critical
    oncall: "true"
  annotations:
    summary: "Error budget burning too fast"
    description: "At current rate, monthly error budget will be exhausted in 2 hours"
```

### On-Call Intervention Scenarios

#### Scenario: Database Connection Pool Exhaustion

**Trigger Conditions:**
- **Primary Alert**: Service availability drops below 95% for 5+ minutes
- **Secondary Indicators**:
  - Database connection errors spike >50 errors/minute
  - Response times exceed 5 seconds (50x SLO violation)
  - Error rate on POST /shorten endpoints >20%

**Symptom Presentation:**
```bash
# Error logs showing connection exhaustion
2026-01-17T10:15:23Z [ERROR] Failed to acquire database connection:
  connection pool exhausted (50/50 connections in use)
2026-01-17T10:15:23Z [ERROR] POST /api/shorten failed:
  context deadline exceeded after 30s

# Metrics showing degradation
url_shortener_db_connections_active 50/50 (100% utilization)
url_shortener_request_duration_p95 5.2s (52x SLO violation)
url_shortener_error_rate 0.23 (23% error rate)
```

**Root Cause Analysis:**
1. **Traffic Spike**: Viral content caused 10x traffic increase
2. **Connection Leaks**: Long-running transactions not properly closed
3. **Slow Queries**: Missing index causing table scans
4. **Resource Exhaustion**: Database CPU at 95%, memory swap active

**On-Call Response Playbook:**

**Immediate Actions (0-5 minutes):**
```bash
# 1. Assess blast radius
kubectl get pods -n url-shortener  # Check healthy replicas
curl http://load-balancer/health    # Verify partial service availability

# 2. Scale application layer
kubectl scale deployment url-shortener --replicas=10  # 2x current capacity

# 3. Database emergency scaling
aws rds modify-db-instance \
  --db-instance-identifier url-shortener-prod \
  --db-instance-class db.r6g.8xlarge \  # 2x CPU/memory
  --apply-immediately
```

**Short-term Mitigation (5-15 minutes):**
```bash
# 4. Enable aggressive connection pooling
kubectl set env deployment/url-shortener \
  DB_MAX_OPEN_CONNS=20 \    # Reduce from 50
  DB_MAX_IDLE_CONNS=5 \     # Reduce idle connections
  DB_CONN_MAX_LIFETIME=5m   # Force connection recycling

# 5. Activate read replica routing
kubectl set env deployment/url-shortener \
  ENABLE_READ_REPLICAS=true \
  READ_REPLICA_WEIGHT=80    # Route 80% reads to replicas

# 6. Emergency circuit breaker
kubectl set env deployment/url-shortener \
  ENABLE_CIRCUIT_BREAKER=true \
  CIRCUIT_BREAKER_THRESHOLD=0.1  # Trip at 10% error rate
```

**Root Cause Resolution (15-60 minutes):**
```bash
# 7. Identify slow queries
docker exec postgres-container \
  psql -c "SELECT query, calls, total_time/calls as avg_time
           FROM pg_stat_statements ORDER BY total_time DESC LIMIT 10;"

# 8. Deploy emergency fixes
# Add missing database index
kubectl apply -f k8s/emergency-migration-job.yaml

# 9. Monitor recovery
watch "kubectl get pods -n url-shortener | grep url-shortener"
watch "curl -s http://load-balancer/health | jq .status"
```

**Communication Protocol:**
```
T+2 min:  Post to #incident-response: "Investigating service degradation"
T+5 min:  Update stakeholders: "Identified DB connection issue, scaling in progress"
T+15 min: Customer communication: "Experiencing delays, estimated resolution in 30 min"
T+45 min: All-clear: "Service restored, post-incident review scheduled"
```

**Success Metrics:**
- **MTTR Target**: <30 minutes to restore service
- **Customer Impact**: <2% of requests failed
- **Error Budget**: Incident consumes <10% of monthly budget
- **Learning**: Documented playbook improvements, monitoring gaps addressed

## Future Enhancements

### Priority 1: Analytics & Business Intelligence (Q1 2026)

#### Advanced Analytics Dashboard
```typescript
// React/Next.js dashboard components
interface AnalyticsDashboard {
  realTimeMetrics: {
    activeUrls: number;           // URLs accessed in last 24h
    clicksPerSecond: number;      // Real-time traffic
    topCountries: Country[];      // Geographic distribution
    topReferrers: Referrer[];     // Traffic sources
  };

  historicalTrends: {
    dailyClicks: TimeSeries[];    // 30-day click trends
    urlCreationRate: TimeSeries[];// New URL creation patterns
    peakTrafficHours: number[];   // Traffic optimization insights
  };
}
```

**Technical Implementation:**
- **Data Pipeline**: Kafka â†’ Spark Streaming â†’ ClickHouse/TimescaleDB
- **Visualization**: Grafana dashboards with drill-down capabilities
- **Real-time Updates**: WebSocket connections for live metrics
- **Export Capabilities**: CSV/JSON export for external analysis

#### Geographic Analytics & CDN Integration
```go
// Enhanced analytics with geolocation
type Analytics struct {
    ShortKey      string    `json:"short_key"`
    VisitTime     time.Time `json:"visit_time"`
    Country       string    `json:"country"`
    Region        string    `json:"region"`
    UserAgent     string    `json:"user_agent"`
    Referrer      string    `json:"referrer"`
    IPHash        string    `json:"ip_hash"`  // Privacy-compliant
}

// CDN edge redirection for global performance
func (h *Handler) GeographicRedirect(c *gin.Context) {
    country := c.GetHeader("CloudFlare-IPCountry")

    // Route to nearest CDN edge for optimal performance
    if url, err := h.service.GetWithGeoRouting(c.Param("key"), country); err == nil {
        c.Header("X-Geo-Route", country)
        c.Redirect(302, url.LongURL)
    }
}
```

### Priority 2: Enterprise Features (Q2 2026)

#### Multi-Tenant User Management
```go
// Domain models for enterprise features
type User struct {
    ID           uuid.UUID `json:"id"`
    Email        string    `json:"email"`
    Organization string    `json:"organization"`
    Plan         PlanType  `json:"plan"`  // Free, Pro, Enterprise
    APIKey       string    `json:"api_key"`
    RateLimit    int       `json:"rate_limit"`  // URLs per hour
}

type URLOwnership struct {
    ShortKey     string    `json:"short_key"`
    OwnerID      uuid.UUID `json:"owner_id"`
    TeamID       uuid.UUID `json:"team_id,omitempty"`
    CreatedBy    string    `json:"created_by"`
    Tags         []string  `json:"tags"`
    Category     string    `json:"category"`
}
```

**Authentication & Authorization:**
- **OAuth 2.0/OIDC**: Integration with Google, Microsoft, GitHub
- **RBAC**: Role-based access control (Admin, Editor, Viewer)
- **API Keys**: Programmatic access with scoped permissions
- **Rate Limiting**: Per-user/organization quotas

#### Bulk Operations API
```go
// Batch processing endpoints
POST /api/v2/bulk/shorten
{
  "urls": [
    {"long_url": "https://example1.com", "custom_key": "ex1"},
    {"long_url": "https://example2.com", "expires_in": 3600}
  ],
  "default_ttl": 86400,
  "tags": ["campaign", "2026-q1"]
}

// Response with batch results
{
  "job_id": "batch-123",
  "status": "processing",
  "total_urls": 1000,
  "processed": 847,
  "success_count": 832,
  "error_count": 15,
  "errors": [
    {"url": "invalid-url", "error": "malformed URL"}
  ]
}
```

### Priority 3: Advanced Security & Compliance (Q3 2026)

#### Malware & Phishing Protection
```go
// URL scanning integration
type SecurityService interface {
    ScanURL(ctx context.Context, url string) (*ScanResult, error)
    GetReputation(ctx context.Context, domain string) (ReputationScore, error)
}

type ScanResult struct {
    URL           string              `json:"url"`
    SafetyRating  SafetyLevel        `json:"safety_rating"`
    Categories    []ThreatCategory   `json:"categories"`
    ScanTimestamp time.Time          `json:"scan_timestamp"`
    Confidence    float64            `json:"confidence"`
}

// Integration with security APIs
func (s *SecurityService) ScanWithMultipleProviders(url string) (*ScanResult, error) {
    // Parallel scanning with multiple providers
    providers := []Provider{
        &VirusTotalAPI{},
        &GoogleSafeBrowsing{},
        &URLVoid{},
    }

    // Aggregate results for higher confidence
    return s.aggregateResults(providers, url)
}
```

#### GDPR & Privacy Compliance
```go
// Privacy-first analytics
type PrivacyCompliantAnalytics struct {
    // No PII storage - only aggregate metrics
    URLMetrics     map[string]int    `json:"url_metrics"`      // Short key â†’ visit count
    CountryMetrics map[string]int    `json:"country_metrics"`  // Country â†’ total visits
    HourlyMetrics  map[int]int       `json:"hourly_metrics"`   // Hour â†’ visit count

    // Differential privacy for sensitive queries
    NoiseLevel     float64           `json:"noise_level"`
    DataRetention  time.Duration     `json:"data_retention"`   // Auto-delete after 90 days
}
```

### Priority 4: Performance & Reliability (Q4 2026)

#### Edge Computing & Global Distribution
```yaml
# Multi-region deployment with edge caching
global_infrastructure:
  regions:
    - name: us-east-1
      role: primary
      services: [api, database, cache]

    - name: us-west-2
      role: secondary
      services: [api, read-replica, cache]

    - name: eu-west-1
      role: secondary
      services: [api, read-replica, cache]

  edge_locations:
    cloudflare_workers: 200+ locations
    aws_lambda_edge: 13 regions
    fastly_edge: 60+ POPs

  failover_strategy:
    primary_failure: auto-failover to us-west-2
    cross_region_sync: <100ms replication lag
    dns_ttl: 60 seconds for rapid failover
```

#### Machine Learning for Traffic Optimization
```python
# Predictive analytics for auto-scaling
class TrafficPredictor:
    def __init__(self):
        self.model = XGBoostRegressor()
        self.features = [
            'hour_of_day', 'day_of_week', 'month',
            'previous_24h_avg', 'previous_7d_avg',
            'trending_score', 'social_media_mentions'
        ]

    def predict_traffic(self, timestamp: datetime) -> int:
        """Predict expected RPS for next hour"""
        features = self.extract_features(timestamp)
        predicted_rps = self.model.predict([features])[0]

        # Scale infrastructure proactively
        if predicted_rps > current_capacity * 0.8:
            self.trigger_scale_up(predicted_rps)

        return predicted_rps

    def optimize_cache_strategy(self, url_patterns: List[URLPattern]) -> CacheConfig:
        """ML-driven cache optimization"""
        # Analyze access patterns to optimize cache hit rates
        hot_patterns = self.identify_hot_patterns(url_patterns)
        return CacheConfig(
            ttl_strategy=self.calculate_optimal_ttls(hot_patterns),
            prefetch_candidates=self.predict_future_accesses(hot_patterns)
        )
```

### Priority 5: Developer Experience & Ecosystem (Ongoing)

#### SDK & Client Libraries
```typescript
// TypeScript/JavaScript SDK
import { URLShortener } from '@company/url-shortener-sdk';

const client = new URLShortener({
  apiKey: process.env.URL_SHORTENER_API_KEY,
  baseURL: 'https://api.short.ly'
});

// Promise-based API with full TypeScript support
const result = await client.shortenURL({
  longUrl: 'https://example.com/very/long/url',
  customKey: 'my-link',
  expiresIn: '24h',
  tags: ['marketing', 'campaign-2026']
});

// Webhook support for analytics
client.onRedirect((event: RedirectEvent) => {
  console.log(`URL ${event.shortKey} accessed from ${event.country}`);
});
```

**Multi-Language Support:**
- **Go SDK**: Native implementation with context support
- **Python SDK**: asyncio support for high-performance applications
- **Java SDK**: Spring Boot integration with connection pooling
- **PHP SDK**: Laravel service provider
- **Ruby SDK**: Rails generator for easy integration

#### GraphQL API for Advanced Queries
```graphql
type Query {
  url(shortKey: String!): URL
  urls(filter: URLFilter, pagination: Pagination): URLConnection
  analytics(shortKey: String!, timeRange: TimeRange): Analytics
}

type URL {
  shortKey: String!
  longUrl: String!
  visitCount: Int!
  createdAt: DateTime!
  expiresAt: DateTime
  owner: User
  tags: [String!]!
  analytics(timeRange: TimeRange): URLAnalytics
}

# Complex queries with relationships
query GetCampaignMetrics($tag: String!, $startDate: DateTime!) {
  urls(filter: {tags: [$tag], createdAfter: $startDate}) {
    edges {
      node {
        shortKey
        visitCount
        analytics(timeRange: {start: $startDate, end: "now"}) {
          totalClicks
          uniqueVisitors
          topCountries(limit: 5) {
            country
            visits
          }
        }
      }
    }
  }
}
```

### Integration Roadmap Timeline

```mermaid
gantt
    title URL Shortener Enhancement Roadmap
    dateFormat  YYYY-MM-DD
    section Analytics
    Advanced Dashboard     :2026-01-15, 45d
    Geographic Analytics   :2026-02-15, 30d
    Real-time Streaming    :2026-03-01, 60d

    section Enterprise
    User Management        :2026-04-01, 60d
    Bulk Operations        :2026-05-15, 45d
    Team Collaboration     :2026-06-15, 30d

    section Security
    Threat Detection       :2026-07-01, 45d
    GDPR Compliance        :2026-08-01, 30d
    Audit Logging          :2026-08-15, 15d

    section Performance
    Edge Distribution      :2026-10-01, 60d
    ML Optimization        :2026-11-01, 45d
    Auto-scaling           :2026-12-01, 30d
```

## Troubleshooting

### Common Issues and Solutions

#### 1. Migration Status Failed

**Error**: `make migrate-status` returns error "The system cannot find the file specified"

**Solution**: Make sure Docker containers are running:
```bash
make docker-up
docker ps  # Should show url-shortener-postgres container
```

#### 2. Connection Refused to Database

**Error**: `Failed to connect to database: connection refused`

**Solution**:
```bash
# Check if PostgreSQL container is running
docker ps | grep postgres

# If not running, start containers
make docker-up

# Wait 10-15 seconds for PostgreSQL to be ready
# Then run migrations
make migrate
```

#### 3. Port Already in Use

**Error**: `bind: address already in use`

**Solution**:
```bash
# Find what's using the port
# Windows PowerShell:
netstat -ano | findstr :8080
netstat -ano | findstr :5432

# Kill the process or change port in .env file
# Edit .env and change SERVER_PORT or DATABASE_PORT
```

#### 4. Migrations Not Applied

**Error**: Migration files exist but `make migrate-status` shows nothing

**Solution**:
```bash
# Ensure you're connected to the right database
make migrate

# If migrations fail, reset database
make db-reset
make migrate
```

#### 5. Docker Compose Errors

**Error**: `Error response from daemon: conflict`

**Solution**:
```bash
# Stop and remove all containers
make docker-down

# Remove volumes if needed (WARNING: deletes all data)
docker-compose down -v

# Start fresh
make docker-up
```

#### 6. Cannot Access Database from Host

**Problem**: `make migrate` works but application can't connect

**Solution**: Ensure `.env` has correct settings:
```bash
# For running app locally with Docker DB
DATABASE_HOST=localhost
DATABASE_PORT=5432

# For running app inside Docker
DATABASE_HOST=postgres  # service name in docker-compose.yml
```

#### 7. Short Key Length Errors

**Error**: `pq: value too long for type character varying(10)`

**Solution**: This means your database schema needs updating:
```bash
# Apply the migration to increase short_key length
docker compose exec postgres psql -U postgres -d urlshortener -c "ALTER TABLE urls ALTER COLUMN short_key TYPE VARCHAR(12);"

# Or rebuild with updated migrations
docker compose down -v
docker compose up -d
```

#### 8. Invalid Short Key Format

**Error**: `invalid short key format`

**Solution**: Custom keys must follow these rules:
- Only alphanumeric characters (a-z, A-Z, 0-9)
- Can include hyphens (-) and underscores (_)
- Maximum 12 characters
- No spaces or special characters

**Valid examples**: `my-link`, `custom_key`, `Test123`
**Invalid examples**: `my link`, `key@123`, `special!char`

### Getting Help

If you encounter issues:

1. **Check logs**: `make docker-logs` to see container output
2. **Check Docker status**: `docker ps` to verify containers are running
3. **Verify environment**: Ensure `.env` file exists and has correct values
4. **Database connection**: Run `make db-shell` to test direct database access
5. **Clean slate**: Run `make docker-down`, `docker-compose down -v`, then start fresh

### Useful Debug Commands

```bash
# Check all environment variables loaded
make help  # Shows all available commands

# View PostgreSQL logs
docker logs url-shortener-postgres

# View Redis logs
docker logs url-shortener-redis

# Connect to database and check tables
make db-shell
\dt              # List all tables
\d urls          # Describe urls table
SELECT * FROM schema_migrations;  # Check applied migrations
```

## License

MIT License

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

#### 1. Migration Status Failed

**Error**: `make migrate-status` returns error "The system cannot find the file specified"

**Solution**: Make sure Docker containers are running:
```bash
make docker-up
docker ps  # Should show url-shortener-postgres container
```

#### 2. Connection Refused to Database

**Error**: `Failed to connect to database: connection refused`

**Solution**:
```bash
# Check if PostgreSQL container is running
docker ps | grep postgres

# If not running, start containers
make docker-up

# Wait 10-15 seconds for PostgreSQL to be ready
# Then run migrations
make migrate
```

#### 3. Port Already in Use

**Error**: `bind: address already in use`

**Solution**:
```bash
# Find what's using the port
# Windows PowerShell:
netstat -ano | findstr :8080
netstat -ano | findstr :5432

# Kill the process or change port in .env file
# Edit .env and change SERVER_PORT or DATABASE_PORT
```

#### 4. Migrations Not Applied


#### 7. Short Key Length Errors

**Error**: `pq: value too long for type character varying(10)`

**Solution**: This means your database schema needs updating:
```bash
# Apply the migration to increase short_key length
docker compose exec postgres psql -U postgres -d urlshortener -c "ALTER TABLE urls ALTER COLUMN short_key TYPE VARCHAR(12);"

# Or rebuild with updated migrations
docker compose down -v
docker compose up -d
```

#### 8. Invalid Short Key Format

**Error**: `invalid short key format`

**Solution**: Custom keys must follow these rules:
- Only alphanumeric characters (a-z, A-Z, 0-9)
- Can include hyphens (-) and underscores (_)
- Maximum 12 characters
- No spaces or special characters

**Valid examples**: `my-link`, `custom_key`, `Test123`
**Invalid examples**: `my link`, `key@123`, `special!char`
**Error**: Migration files exist but `make migrate-status` shows nothing

**Solution**:
```bash
# Ensure you're connected to the right database
make migrate

# If migrations fail, reset database
make db-reset
make migrate
```

#### 5. Docker Compose Errors

**Error**: `Error response from daemon: conflict`

**Solution**:
```bash
# Stop and remove all containers
make docker-down

# Remove volumes if needed (WARNING: deletes all data)
docker-compose down -v

# Start fresh
make docker-up
```

#### 6. Cannot Access Database from Host

**Problem**: `make migrate` works but application can't connect

**Solution**: Ensure `.env` has correct settings:
```bash
# For running app locally with Docker DB
DATABASE_HOST=localhost
DATABASE_PORT=5432

# For running app inside Docker
DATABASE_HOST=postgres  # service name in docker-compose.yml
```

### Getting Help

If you encounter issues:

1. **Check logs**: `make docker-logs` to see container output
2. **Check Docker status**: `docker ps` to verify containers are running
3. **Verify environment**: Ensure `.env` file exists and has correct values
4. **Database connection**: Run `make db-shell` to test direct database access
5. **Clean slate**: Run `make docker-down`, `docker-compose down -v`, then start fresh

### Useful Debug Commands

```bash
# Check all environment variables loaded
make help  # Shows all available commands

# View PostgreSQL logs
docker logs url-shortener-postgres

# View Redis logs
docker logs url-shortener-redis

# Connect to database and check tables
make db-shell
\dt              # List all tables
\d urls          # Describe urls table
SELECT * FROM schema_migrations;  # Check applied migrations
```

## License

MIT License

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.
